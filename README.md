# ğŸ§  BCI-Flystick  
### OpenBCI-based Real-Time EEG â†’ Virtual Joystick Bridge for Drone & Flight Simulation Control

---

## ğŸš€ Overview

**BCI-Flystick** is an open-source framework that converts real-time EEG signals from the **OpenBCI Cyton** board into a **three-axis virtual joystick**.  
It decodes **motor-imagery (Î¼/Î²)** and **visual-attention (Î±/SSVEP)** patterns to control yaw, altitude, and throttle, enabling brain-driven flight in drone simulators or robotic testbeds.

> â€¢ **Yaw (left/right rotation)** â† C3/C4 Î¼Î² lateralization  
> â€¢ **Altitude (up/down)** â† Cz Î¼Î² ERD intensity  
> â€¢ **Speed (throttle)** â† Oz Î± power decrease or SSVEP frequency response  

---

## âœ¨ Key Features

| Feature | Description |
|----------|-------------|
| ğŸ§ **EEG Acquisition** | Real-time data streaming from OpenBCI Cyton (8 channels) |
| ğŸ§® **Signal Processing** | Î¼/Î² ERD for motor imagery and Î±/SSVEP for attention control |
| ğŸ® **Virtual Joystick Output** | vJoy (Windows) or uinput (Linux) creates a USB joystick device |
| ğŸ”— **Simulator Integration** | Works with PX4 SITL + QGroundControl, Mission Planner, AirSim, VelociDrone |
| ğŸ§° **Config-Driven Design** | JSON + YAML for channel mapping and parameter tuning |
| âš™ï¸ **Extensible Architecture** | Python feature extraction + Rust receiver for low-latency control |

---

## ğŸ§© System Architecture
```text
EEG (C3, C4, Cz, Oz)
        â†“    
   OpenBCI Cyton 
        â†“      
  BrainFlow SDK (Python)
        â†“        
 Feature Extraction (Î¼, Î², Î±, SSVEP) 
        â†“      
   UDP Stream (Yaw, Alt, Speed)  
        â†“       
 Virtual Joystick (vJoy / uinput) 
        â†“       
 Drone Simulator / Game Engine
```
## ğŸ› ï¸ Installation & Setup
1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/Skiyoshika/BCI-Flystick.git
cd BCI-Flystick
```
2ï¸âƒ£ Setup Python Environment
```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r python/requirements.txt
```
3ï¸âƒ£ Configure Channels
Edit config/channel_map.json:

```json
{
  "serial_port": "COM3",
  "board_id": "CYTON",
  "channels": { "C3": 0, "C4": 1, "Cz": 2, "Oz": 7 }
}
```
4ï¸âƒ£ Start Controller
```bash
python python/bci_controller.py
```
The system performs ~25 s baseline calibration, then streams Yaw / Altitude / Speed.

5ï¸âƒ£ Connect to Virtual Joystick

**Windows (vJoy):**

```bash
python python/feed_vjoy.py
```
**Linux (uinput):**

```bash
sudo python python/feed_uinput.py
```
A virtual joystick will appear and be recognized by QGroundControl / AirSim / Mission Planner.

## ğŸ•¹ï¸ Flight Simulation Integration
**âœˆï¸ QGroundControl / PX4 SITL**

Bind axes:

X â†’ Yaw

Y â†’ Altitude

Z â†’ Throttle (Speed)

Calibrate sensitivity & dead zones (recommended 5â€“10%).

**ğŸš Mission Planner (ArduPilot)**

Enable Joystick Input and assign channels.

**ğŸ•Šï¸ AirSim / VelociDrone**

Select Controller / Joystick mode; vJoy/uinput is detected automatically.

## ğŸ“‚ Project Structure
```text

bci-flystick/
â”œâ”€ config/      # Channel mapping & signal parameters
â”œâ”€ python/      # Core controller + virtual joystick scripts
â”œâ”€ rust/        # Low-latency UDP receiver and SDK bridge
â”œâ”€ scripts/     # Quick start helpers
â””â”€ docs/        # Documentation and experiment notes
```
## ğŸ“œ License
MIT License â€“ Open-source, free to modify and distribute.

You may freely use this project for research, education, or development.

## ğŸ“§ Contact
**Author:** @Skiyoshika

**Email:** hiuramika122@gmail.com

**Keywords:** Brainâ€“Computer Interface, OpenBCI, EEG, Drone Control, vJoy, AirSim, PX4

## ğŸŒŸ Acknowledgements
OpenBCI Cyton Board

BrainFlow SDK

vJoy Virtual Joystick Driver

PX4 SITL & QGroundControl

AirSim (Microsoft)
